{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PidSfe7Sk0O_",
    "outputId": "0bbeb265-1fcf-4d40-be9a-156dfcdda5c1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4tIXdselT7U",
    "outputId": "3aecb317-6b9f-4e09-bd19-c2e3c914c34d"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/Datasets/audio_speech_actors_01-24.zip\" -d /content/ravdess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5dppxsCQXD-",
    "outputId": "651fa9bb-a48b-4935-8eba-33e78d360136"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torchaudio librosa evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqAT-A1TR1Rb",
    "outputId": "0f5b3379-89e6-43c6-ae60-dc79c9f64a74"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cfn4FZVQbDf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpZZWW4EQ63P"
   },
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6tfb_D7iQ-WA",
    "outputId": "146485bd-814e-4862-ec89-bd6650b59370"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"/content/ravdess/audio_speech_actors_01-24\"\n",
    "\n",
    "filepaths = []\n",
    "emotions = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "\n",
    "            parts = file.split(\"-\")\n",
    "            emotion_code = parts[2]   # âœ… THIRD number = emotion\n",
    "\n",
    "            filepaths.append(os.path.join(root, file))\n",
    "            emotions.append(emotion_map[emotion_code])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"path\": filepaths,\n",
    "    \"emotion\": emotions\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "oBtDDlbaRBIW",
    "outputId": "81c81436-f7f1-4d5c-a66a-76e27d7ed826"
   },
   "outputs": [],
   "source": [
    "label_list = sorted(df[\"emotion\"].unique())\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "df[\"label\"] = df[\"emotion\"].map(label2id)\n",
    "\n",
    "print(label2id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Fl2qdgnREf3",
    "outputId": "02ceb6f6-c360-4900-9c65-ee0337660a1f"
   },
   "outputs": [],
   "source": [
    "print(\"Total samples:\", len(df))\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df[\"emotion\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361,
     "referenced_widgets": [
      "99ea86d235234341a5a1032902b59939",
      "768baf2549ee43bf91ed49661946a479",
      "177cfe2db9a54da8923c769966256eaa",
      "9e9d7fd0f10a4db789dd2a1bca54bb22",
      "bcde9c201c6b40219ab1db08b475079a",
      "2cba96c28ead45619a08a0d98701e1a2",
      "e1482c4146be4ce1bd964e290c6c2bd7",
      "50bfa5cc956542d09512a43e311cd457",
      "fc6dcf544ae44622ab01fdf2964cd8a8",
      "2ccc61d413f54167b15cc893c3ed7648",
      "d0a9953e27274320a67567a3d9072ffc"
     ]
    },
    "id": "haWlt_bgRRLF",
    "outputId": "78cfed6b-cc8c-4009-aa2e-d54171edd8e8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "model_name = \"facebook/wav2vec2-base\"\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPVkWw7YRW8_"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    speech, sr = librosa.load(example[\"path\"], sr=16000)\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        speech,\n",
    "        sampling_rate=16000,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=16000 * 5,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_values\": inputs[\"input_values\"][0],  # remove batch dim\n",
    "        \"labels\": example[\"label\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "7bd2b3cf3a6840d687f771ce99e46d99",
      "333450689bff4cb59b7114aba8eebccf",
      "15ae88113f4746f1ae46bb92e032993c",
      "8f5d2b6daf9145fea74c9471cca44fee",
      "6bc588541489473a99a79efac0b56dad",
      "ee4de94e689540c1ae89ce599d4dcfed",
      "83052370a07e4cd98eb095366518d4e4",
      "5ded6ddf52224be1b248f640ecde33e8",
      "6d0fd7f23e20407fa9b67d255240eb3b",
      "126c3ea817f344c99d258a477d01e147",
      "48320d51e11a44c58355ea821e3499a9",
      "ef2b3c97cfbc4cc9b9848a36fb2019c3",
      "5e9fb966482941fab015681501711bb9",
      "f9870ba521eb48bbb3846be02572fcd4",
      "e8d3284e660e4bb9b961efed304218fa",
      "5680517ac932451592cdfea9d7d27329",
      "34dae38eebd1486890febb7836982f43",
      "e8dcc9a9357e485fa1095dbdaa37d4a0",
      "00ac84386f3940919c8f90c99579de69",
      "27f662ae97004b6c98fee2491042a799",
      "bcb76644b64c48848aa1ca9c09672bb4",
      "7876d3efeeb745c880307af4cf16aae1"
     ]
    },
    "id": "c41SbjNKRakN",
    "outputId": "c16c8ae9-7397-4d81-bcbc-a997d22f4690"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df[[\"path\", \"label\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "dataset = dataset.map(preprocess_function, remove_columns=[\"path\"])\n",
    "\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_values\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-76_YwPRhrE"
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSlKYXNpSf2d"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoUmefpQWtXj",
    "outputId": "e6ca7ac1-796d-4ea4-fce6-8e7ba94f610b"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./emotion_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELHBU5b0SiNn"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpwavQ7lWR_o"
   },
   "outputs": [],
   "source": [
    "# Freeze CNN feature extractor\n",
    "model.freeze_feature_encoder()\n",
    "\n",
    "# Unfreeze last 2 transformer encoder layers\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder.layers.10\" in name or \"encoder.layers.11\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744,
     "referenced_widgets": [
      "632ef1078e464d06bdb8e9e81c2d575d",
      "259e3a1c769d425e8f7725b314a19862",
      "0ca38c6894dd491292d0b394d053f9c2",
      "517d24e95318429ba96fc28e6952d236",
      "a54936f21ee944f99251a2dd184a471c",
      "2bbc493b12964f56b7c1c4c295ce7bb9",
      "bc754fca750842d38cfa458488aed598",
      "8efa9d4a32dd429ba348b8181cd0f22b",
      "cbec1378bbd44e679a68e92aaf700d2d",
      "fc93aa3458db46bab5fee294252733ce",
      "c1993995397047118f618cc867b46f88",
      "53351a25bafa457397f2b6d27d00cc08",
      "dd06dc72813642a392f6f7954bae64c8",
      "0e83963bbb8748d0bc38ad1b1a88c194",
      "74f1bd60aafe4f488baaf8c7c70f4b6a",
      "861490f2f6774f70b0172f435fb0f8b2",
      "62a9eaf9307e4f5cb41b9538cc7ebab2",
      "c7277558be8d4b9dbc7bdfd836c8bde3",
      "670f4e2589d6441bbd0def0e2aed082c",
      "0b9b911b89a34c1fa0731450757a6215",
      "fc07eb7ea7b6473280db40b633f4cab3",
      "0051d493aa9043d28545f6652a176bbb",
      "e6e5bd7b4962469a81ea000a4c5749f8",
      "d75ca891f0804a3fa606b5128a3985a5",
      "07fae478a7824322b9aad0bfc98cdbe1",
      "74eb1f86b4284358950768e0ebb8399b",
      "f77530562e08479fa1176228f72abbd7",
      "0bae12b75cd647e78fad1ad3a91a87b5",
      "2495cc9f49db49409da5ab612d123baa",
      "5998e1e4fa7c4b588b02570ecb3cee0a",
      "907f4caf0f7c42e5a180f0e6ebd0f084",
      "cb603b0d1dcf449cad4cc086eaa3a123",
      "2559be11551741cdab052274e43eda27",
      "9cd7706fcc8f4c7e83047a6100c744f9",
      "08c595230c524453a91234f3963bdbd0",
      "dcb83f30160142ef8bf9de1d075a5f74",
      "45640336f0534c32a4a71d2ccadbb51c",
      "b1259b039ced45b88205d9d38a7753b6",
      "2ab569c3103c4e189367c9d164ef45c6",
      "3b857862e7e449f5929059602642e8d8",
      "6d61b2692f0e4705af041e6950375b91",
      "4481ff46e2814f9fa844c6f399689d69",
      "0f9bfad351634ce0b28d74b5a7fdf26c",
      "4e4ba6510f814c0f93250b5561035cdf",
      "8ac14423ab0b479cb6ead4a17aace0b5",
      "ef3ffa78756d4384bb31c4b33b1fecf4",
      "c10837c1635942c093f4a8163be59c42",
      "de009c3780164b77bcd3882d68410239",
      "e480e5d898e74e0e8ee2cb5efa18f66a",
      "bbca54dcf1a74c3ba705deab3542bed4",
      "f3ec5f343afe4e0e94330b233ab01f01",
      "739c7fdf4a6d46a4819fadab643bb902",
      "d6d7dd217568453d8e72bd6aa64795c5",
      "2d5c05e3a0fc404ca056021755de8164",
      "3ef21fdf1d15496f9ba119a766cb5be2",
      "480da03a9bf047ebb786bdcf5710eb86",
      "6935cb8e456643ac8b5c121e563b26ab",
      "537533b32e91446eb5d7a23e0e5f8a5a",
      "4a387520cfc2463e821e33a95c92f3cc",
      "c858330066754c7d9accd075355207f6",
      "a9d7dc0dd5de43179435b2f4fa5f8393",
      "e4b5aa95f2634e699616a814d41f3da8",
      "a5059f04224c4d85aa135378fa0f167d",
      "eaa9b46008ae45589c6d700b518ebf06",
      "0962090731324e939ca1e0534e5bf3a1",
      "41d648d081d9445b8e1af4c7b05f487c",
      "05d6dd4a5c564a29b0d881ad74298f35",
      "432fbabe729541fe95ef2dd6f64fcb15",
      "5723e14f08ca47c69e5d95071a275f9c",
      "2286dc21c7e4460895d6dbc51069ab2a",
      "66ca9fd30ef14747815aa7bf7db896ee",
      "8d08ef34e7d648408abc62e9ccfca3d6",
      "80dbbe6fed364427931beeda85ae0b25",
      "a2216a85645e4f01a1029084ccbb7c36",
      "25e6b0e80be9463087f225aa7fa7dae9",
      "49e7d4e8b73a473c98547b61c5b9854a",
      "ad3df2c39a494027b2d257d4339ceb9f",
      "3a1f69e0e0194630886399a53d623f98",
      "998f4076c3e345edbdbdc462ba328d7e",
      "262cf5b80a6f43e0ad5f27a14587dd65",
      "a4c2a944826841f5bd3a85912341f604",
      "96249e23e01b426bb44c452ee9d12d17",
      "d50823592afb4625bee3f63c1436f347",
      "47c3d3a800de49f491030ba839b5559d",
      "d7620874563c4bdea8fce6924a339939",
      "c45141b3bf85449e8adc65d1a7bb1481",
      "1ae905dcd2e04167b52350cf491a3412",
      "6404657649f946a99d65229396a5d219",
      "00f7ba4722a542c8a56358a19b7663d3",
      "7615d08cd4224948a4e7ad9c431d9675",
      "b1b3a332de504f49b01d869bf4985c94",
      "658f3309a6ab462e990f6a3499bd8853",
      "ad3a0c9e20a24ce08b71b5c28ff803c1",
      "e1de848b2d6441aaa6f4b7e2efbe9fe1",
      "3b6824b0c038472792e6977c40d6ddc4",
      "8126b4a58c724ec7992ecd055797ce8f",
      "2110c397e5104be6aa376b5422c9ff13",
      "34988063d467439f9838da149caec3f5",
      "49235943d5d742ac91a44bbf7cf755d5",
      "362d061fd1e946f3a9179aca6a9e4cb0",
      "cc73a807f8c64d29b9a85aa8b8ff0f91",
      "646d3612853745ef93de26fa76ff80a9",
      "43d2bbbb055b444fa6eb5ffdeaca17bb",
      "bd9e9c042e194ceca50c3d3e73e7d66c",
      "2e757993aef8494aa9ddd49c1ab29036",
      "d4042dd33f67401cbea21666d7c91282",
      "ecea55b209d94ffa893b66b84a8e424b",
      "5b09faf3a14149c19d53cbb56480e696",
      "f84b176398be4d07a07318a46a51da92",
      "ca3257ec7305423fbc33762df9e926ca"
     ]
    },
    "id": "Fzo5178-StSr",
    "outputId": "21eb8dc2-728e-485a-c114-69edc02199ac"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "03edd92c246a423f9a3fcf58be0e08a3",
      "7261994ced8640599f6afc9f30c4767a",
      "f7563d48f2f948039b9414f281237755",
      "9986e99776ff4896a13b2a166387f821",
      "dc155d7762ce48e89c78f60251398507",
      "f5303235f729493a91337eb5a34a83ae",
      "8d341fb1ce59463aabf0b31d5b88f118",
      "4aed2de598184a9aa8129c77b1c785af",
      "0eafbcde1ce1431a9a2fa4e53632aae2",
      "6bfb857e433b442aa944ac81e36e348f",
      "ee7084f225a1405492a9474632846bcc"
     ]
    },
    "id": "lq8x_doQYogz",
    "outputId": "7ed218ca-1b60-49a3-d42d-1550b4086a9d"
   },
   "outputs": [],
   "source": [
    "save_path = \"/content/emotion_wav2vec2_model\"\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "feature_extractor.save_pretrained(save_path)\n",
    "\n",
    "print(\"Model saved to:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vp8UCzQzYshU",
    "outputId": "ef484271-b634-4ce9-ad9f-71f0805dc49c"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"/content/emotion_wav2vec2_model\", 'zip', save_path)\n",
    "\n",
    "print(\"Zipped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UPtUZqTQY06H",
    "outputId": "84b3dce5-6183-4878-bd7c-6bb88bd3aa2e"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(\"/content/emotion_wav2vec2_model.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
